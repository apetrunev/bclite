.ds CH
.ds LH
.ds RH 
.ds CF %
.
.nr HM 0.9i
.nr PS 12
.nr VS 14
.nr FL \n[.ll]
.wh 0.2i HR
.
.de HR \"Heading for pages
.
.ce 100
.ps 8 
.vs 10
Кафедра математического моделирования и кибернетики 
\l'6i' 
\f[I]Интерпретируемый язык для вычислений с плавающей точкой IEEE  754 \f[P]
.ps
.vs
.ce 0
.sp 3
.
.. \" HR
.
.B
\s+2Введение\s0
.PP
Первые компьютеры как известно были не только огромных размеров,
но и программировались очень долгим и трудным способом \(em
с помощью нулей и единиц (машинный код).
Тогда считалось что время компьютера более значимо
чем время программиста. Со временем как размер программ стал расти,
стало очевидным, что требуется более надежная (менее подверженная ошибкам)
форма записи.
.PP
Для облегчения задач программирования были изобретен язык ассемблера.
Первоначально ассемблерные языки представляли собой мнемоническое обозначение машинных операций.
Позже функциональность ассемблера была расширена за счет появления макросов.
.PP
Программирование на ассемблере тесно связанно с архитектурой процессора.
Потому как для каждой архитектуры существует свой ассемблер,
то процесс написания переносимых программ остается проблемой.
Данную проблему были призваны решить языки высоко уровня.
Потребность в которых была четко обозначена.
И тогда в середине 50-х годов появился язык \f[I]Фортран\f[P]\**.
.PP
Сегодня существует огромное количество языков высокого уровня.
Их область применения также огромна,
от языков общего назначения (С/С++, Java, Fortran и др.)
до специализированных (SQL, AWK, Matlab и др.).
Но все они опираются одни и те же базовые принципы,
используя которые мы можем создать наш собственный язык.
.PP
Так же языки программирования можно разделить на
\f[I]интерпретируемые\f[P] и \f[I]компилируемые\f[P].
В интерпретируемых языках исходный код программы не преобразуется
в машинный код, а исполняется с помощью программы \f[I]интерпретатора\f[P].
Интерпретаторам и посвящена данная работа.
.
.FS 
\fBФортран\fP (Fortran) \(em первый язык высокого уровня,
а точнее его первый диалект, который появился в середине 50-х,
в последствие значительно эволюционировавший. 
В те годы наиболее распространенными были программы вычислительного характера.
А язык Фортран в свою очередь являлся главным инструментом в научных и инженерно-технических вычислениях.
На сегодняшний день существую огромное количество библиотек написанных на Фортране, 
находящихся в открытом доступе.
.FE
.PP
Посмотрим несколько подробнее на то
что представляет собой интерпретатор.
Интерпретатором обычно считается компьютерная программа
выполняющая инструкции на языке программирования.
Примером такой программы может служить \f[I]Octave\f[P]\**.
В некотором смысле центральный процессор также является интерпретатором,
поскольку выполняет машинные инструкции.
.PP
Перед тем как выполнить инструкции интерпретатор
переводит их в некоторое промежуточное представление.
.FS
\f[B]Octave\f[P] или \f[B]GNU Octave\f[P] \(em свободная система для математических вычислений
использующая совместимый с \f[B]MATLAB\f[P] язык высокого уровня.
.FE
.
.RS
.ps 10
.vs 12 
.PS
I:box width 1.5 "\f[C]Интерпретатор\f[P]"
move
arrow right at 1/2 <I.se, I.ne> 0.1
R:box invisible width 1 "\f[C]Результат\f[P]"
{
 B1: box wid 1 at (I.nw + (-1, 0.1)) "\f[C]Исходная\f[P]" "\f[C]программа\f[P]"
 B2: box wid 1 at (I.sw + (-1, -0.1)) "\f[C]Входные\f[P]" "\f[C]данные\f[P]"
 arrow from B1.e to 2/3 <I.sw, I.nw>
 arrow from B2.e to 1/3 <I.sw, I.nw>
}
.PE
.ps
.vs
.ce
\fBРис. 1.\fP Модель по которой работает интерпретатор 

.RE
.
.PP 
Как уже говорилось, перед тем как выполнить инструкции интерпретатор
транслирует эти инструкции в некоторое эквивалентное \f[I]промежуточное представление\f[P].
Если взглянем более подробно то увидим что трансляция кода в промежуточное представление
состоит из двух частей: \f[I]анализа\f[P] и \f[I]синтеза\f[P].
.PP
В части анализа программа разбивается на составные части,
на которые накладывается грамматическая структура.
Затем с использованием этой структуры создается промежуточное представление исходной программы.
Если в части анализа обнаруживается, что сходная программа грамматически или семантический неверна,
то об этом следует информировать пользователя.
Фаза анализа также собирается информацию о программе,
помещая ее в специальную структуру \(em \f[I]таблицу символов\f[P],
которая передается дальше, в часть синтеза.
.PP
В интерпретаторе часть синтеза несколько отлична от аналогичной части в компиляторе.
В отличие от компилятора, интерпретатор не создает бинарный файл.
В место этого, он выполняет инструкции используя промежуточное представление и таблицу символов.
.bp
.
.NH 1
Схема интерпретирования
.LP
Процесс интерпретирования или по другому трансляции, делится на фазы:
.RS
.IP \[bu] 2
Лексический анализ.
.IP \[bu]
Синтаксический анализ.
.IP \[bu]
Семантический анализ.
.IP \[bu]
Промежуточное представление.
.IP \[bu]
Выполнение
.RE
.PP
Каждая фаза отображается одно промежуточное представление в другое.
Графически это можно изобразить следующим образом:
.RS
.ps 10
.vs 12
.PS
down
box invisible width 2.4 height 0.1 "\f[C]Поток символов\f[P]"
arrow 0.15
box width 2.5 "\f[C]Лексический анализатор\f[P]"
line 0.1
box invisible width 2.2 height 0.1 "\f[C]Поток токенов\f[P]"
arrow 0.15
box width 2.5 "\f[C]Синтаксический анализатор\f[P]"
line 0.1
box invisible width 2.2 height 0.1 "\f[C]Синтаксическое дерево\f[P]"
arrow 0.15
box width 2.5 "\f[C]Семантический анализатор\f[P]"
line 0.1
box invisible width 2.2 height 0.1 "\f[C]Синтаксическое дерево\f[P]"
arrow 0.15;
box width 2.5 "\f[C]Обход дерева\f[P]"
arrow 0.15
box invisible width 2.2 height 0.1 "\f[C]Результат\f[P]"
move left  from 5th box .w
box width 2 "\f[C]Таблица символов\f[P]"
.PE
.ps
.vs
\fBРис. 2.\fP Схема интерпретирования.
Исходная программа переходит из одного промежуточного представления в другое

.RE
.
.PP
Как видно из схемы, конечным промежуточным представлением 
является \fIсинтаксическое дерево\fP. 
Оно формируется в фазе синтаксического анализа и передается дальше
в семантический анализ, где выполняются некоторые проверки. 
Далее совершая обход это дерево мы получаем результат.
.NH 1
Лексический анализ
.PP
Задача лексического анализатора заключается в формировании \fIлексем\fP\**
из потока входящих символов.
Для каждой \fIлексемы\fP затем создается соответствующий \fIтокен\fP\**,
который имеет следующий вид:
.sp
.ce
\f[C]\s-2<имя_токена, значение_атрибута>\s0\f[P]
.sp
.FS
В контексте лексического анализа, \f[B]лексема\f[P] представляет собой последовательность символов.
.FE
.
.FS
\f[B]Токен\f[P] в свою очередь это последовательность символов, то есть это та же \f[B]лексема\f[P], только уже
отнесенная к некоторой категории(Identifier, Number и т.д.) то бишь категоризованная.
.FE
.
.LP
Иными словами, лексический анализатор видит исходный код программы как последовательность  токенов.
Для примера рассмотрим выражение:
.sp
.ce
.CW
\s-2a = b + 10.0\s0
.sp
.LP
Лексический анализатор видит это выражение как:
.ce
.sp
.CW
\s-2<id, a> <=> <id, b> <+> <10.0>\s0
.sp
.RS
.IP \[bu] 2
Лексема \f[C]a\f[P] отобразится в токен \f[C]<id, a>\f[P].
Где \f[C]id\f[P] это абстрактный символ обозначающий \f[C]identifier\f[P],
тогда как \f[C]a\f[P] указывает на запись в таблице символов.
.sp
.IP \[bu] 2
Символ присваивания отображается в токен \f[C]<=>\f[P].
В данном случаю значение атрибут нам не нужно,
поэтому оно опускается.
.sp
.IP \[bu] 2
Символ \f[C]b\f[P] отображается в токен \f[C]<id, b>\f[P],
с соответствующей записью в таблице символов.
.sp
.IP \[bu] 2
Символ \f[C]+\f[P] отображается в токен \f[C]<+>\f[P].
.sp
.IP \[bu] 2
Число \f[C]10.0\f[P] отображается в токен \f[C]<10.0>\f[P].
.sp
.RE 
.
.PP
Пробельные символы разделяющие лексемы лексическим анализатором пропускаются.
В контексте нашей программы, поток токенов выглядит как:
.LP
.CW
.ce
.sp
.nf
\s-2TOKEN_ID \(-> TOKEN_ASSIGN \(-> TOKEN_ID \(-> TOKEN_PLUS \(-> TOKEN_DIGIT\s0
.fi
.sp
.PP
Лексический анализатор реализован как функция и вызывается из синтаксического анализатора,
возвращая один токен за один раз. Таким образом если лексический анализатор встретил число  
\f[C]10.0\f[P] то синтаксический анализатор получит целое число \f[C]TOKEN_DIGIT\f[P],
а значение атрибута будет \f[C]10.0\f[P]. Глобальная переменная которая содержит всю информацию о токене выглядит как:
.RS
.sp
.CW
.nf
struct lex {
	token_t		token;
	union {
		char    *id;
		double  real;
		char    *string;
	};
};
.fi
.sp
.RE
.PP
В фазе лексического анализа значительно сокращается поток входных символов,
путем группирования их в токены. Что упрощает работу следующей фазе.
.
.NH 2
Регулярные выражения\**
.PP
Регулярные выражения помогают нам  определить токены которые лексический анализатор
должен распознать. Для конструирования регулярных выражений нам помогут следующие операции:
.FS
\f[B]Регулярные выражения\f[P] дают удобный способ определения строк в тексте:
символы, слова, и т.д.
.FE
.
.RS
.IP \[bu] 2
\f[C]+\f[P] \(em указывает на один и более предшествующих элементов.
.IP \[bu] 2
\f[C]?\f[P] \(em указывает на ноль или один предшествующий элемент.
.IP \[bu] 2
\f[C]*\f[P] \(em указывает на ноль и более предшествующих элементов.
.RE
.
.PP
Теперь посмотрим на сами выражения.
.
.RS
.IP \[bu] 2
\fIПробельные символы\fP лексическим анализатором пропускаются.
То есть для них не генерируются токены. Обозначим их как:
.CW
.ce
.sp
ws \(-> (blank|tabs)+
.sp
.IP \[bu] 2
\fIЦифры\fP
.ce
.CW
.sp
digit \(-> [0-9]
.sp
.IP \[bu] 2
\fIЧисла\fP целые и с плавающей  точкой
.CW
.ce 2
.sp
digits \(-> digit+
.sp
.CW
number \(-> digits(.digits)?(E[+|-]?digits)?
.sp
.IP \[bu] 2
\fIАнглийские буквы\fP в верхнем и нижнем регистре
.CW
.ce
.sp
letter \(-> [A-Za-z_]
.sp
.IP \[bu] 2
\fIИдентификаторы\fP могут начинаться с символа подчеркивания или буквы:
.CW
.ce
.sp
id \(-> letter_[letter_|digit]*
.sp
.IP \[bu] 2
\fIОперации\fP
.CW
.ce 100
.sp
assign_op \(-> =
.CW
.sp
arith_op \(-> +|-|*|/|%
.CW
.sp
rel_op \(-> <|>|<=|>=|==|!=
.CW
.sp
not_op \(-> !
.CW
.sp
logic_op  \(->|| | &&
.ce 0
.IP \[bu] 2
\fIОсновные символы\fP
.ce
.CW
.sp
basic_sym \(-> { | ( | [ | } | ) | ] | . | , | ; | &
.sp
.IP \[bu] 2
\fIКлючевые слова\fP
.ce 100
.CW
if \(-> if
.sp
.CW
else \(-> else
.sp
.CW
for \(-> for
.RE
.NH 2
Ключевые слова
.PP
Каждый язык программирования имеет набор ключевых слов.
Ключевое слово, является таким же идентификатором \fCid\fP. 
Когда лексический анализатор находит идентификатор,
он просматривает таблицу, если данный \fCid\fP является ключевым словом, 
то лексический анализатор возвращает для него токен,
в противном случае возвращается \fCTOKEN_ID\fP с именем идентификатора в качестве значения атрибута.
.PP
Таким образом каждое ключевое слово имеет свой токен:
.RS
.CW
.ce 100
.nf

for \(-> TOKEN_FOR

if \(-> TOKEN_IF

else \(-> TOKEN_ELSE

while \(-> TOKEN_WHILE

.fi
.ce 0
.RE
.NH 2
Таблица ключевых слов
.PP
Как уже говорилось когда лексический анализатор находит идентификатор,
ему нужно узнать является ли он ключевым словом или нет.
Для хранения данных таблица ключевых слов использует хэш(hash).
Перед тем как начать работу таблица инициализируется ключевыми словами.
.PP
Для представления ключевого слова используется простая структура.
Где \fCname\fP \(em имя ключевого слова, а \fCtoken_t\fP тип токена.
.RS 
.CW
.nf

struct keyword {
	char    *name;
	token_t	type;
};

.fi
.RE
.LP
Следующая часть кода из лексического анализатора показывает как происходит обработка ключевых слов:
.RS
.CW
.nf

keyword = keyword_table_lookup(id);

if (keyword != NULL) {
	lex.token = keyword->token;
	return lex.token;
} 
 
lex.token = TOKEN_ID;
lex.id    = ustrdup(id);
return TOKEN_ID;	

.fi
.RE
.PP
Код был упрощен, чтобы показать суть.
\fCid\fP здесь это проверяемая строка.
Функция делающая поиск по таблице,
является "обверткой" над функцией поиска для хэш-таблицы.
Если мы находим совпадение в таблице ключевых слов,
то возвращается  тип токена из поля \fCtype\fP.
В противном случае мы возвращаем \fCTOKEN_ID\fP ,
а значение атрибута помещаем найденную строку.
.
.NH 1
Cинтаксический анализ
.PP
Синтаксический анализатор или \fIпарсер\fP знает обо всех конструкциях языка.
Как уже говорилось ранее парсер получает 
токены от лексического анализатора. Его задача построить онднозначное дерево.
То есть после работы парсера код программы отображается в древовидную форму.
.NH 2
Контекстно свободные грамматики
.PP
Работа парсера построена вокруг правил.
Данные правила описывают конструкции языка.
То есть является его формальным описанием.
Для записи эти правил мы используем \fIконтекстно свободные грамматики\fP.
.LP
.nf
Грамматики состоят из следующих компонентов:
.fi
.RS
.IP \[bu] 2
терминалов (или токенов);
.IP \[bu] 
нетерминалов (или синтаксических переменных);
.IP \[bu] 
продукций (правила разбора);
.IP \[bu] 
один из нетерминалов должен быть \fIстартовым символом\fP;
.RE
.PP
Терминалами называются основные символы языка. Нетерминалы состоят из терминалов, 
которые организуются некоторым образом, что бы описать синтаксическую конструкцию.
Продукции имеют следующую структуру: нетерминал с левой стороны продукции,
называемый \fIлевой частью\fP, и \fIтелом проудкции\fP с правой, представляющим собой набор из нетерминалов.
Обе части разделяются знаком \(->, в правой части мы можем использовать символ \fI |(or)\fP,
чтобы описать альтернативный вариант.  
.PP
Для того чтобы немного прояснить ситуацию, рассмотрим случай.
Предположим, что нам нужна грамматика для описания выражения \fC9 + 5 -3\fP.
Правила описывающие данную грамматику выглядят так:
.RS
.nf
.CW

list  \(-> list + digit | list - digit
digit \(-> 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9

.fi
.RE
.PP
Каждая из этих грамматик является продукцией.
С слева стороны находится левая часть или заголовок, а справа тело продукции.
\fClist\fP и \fCdigit\fP являются нетерминалами.
Где \fClist\fP является стартовым символом, потому что его продукция дана первой.
Согласно нашей договоренности символы \fC+ - 0 1 2 3 4 5 6 7 8 9\fP являются терминалами.
.PP
Далее наша задача с помощью имеющейся грамматики "породить" приведенный выше пример.
Грамматика порождает строку, начиная со стартового символа, повторно заменяя нетерминалы
телами продукций для этих нетерминалов. 
То есть строка терминалов может быть порождена начиная со стартового символа формирующего язык,
который определен с помощью грамматик. Собственно это и входит в задачу парсера,
узнать возможно ли породить строку терминалов из имеющихся правил грамматики.
Если это не возможно, то следует оповестить пользователя об ошибке.
.PS
.PE
.NH 2
Ассоциативность операций
.PP
Следующий момент о котором стоит упомянуть является ассоциативность операций.
Ассоциативность возникает тогда, когда мы имеем операции одинакового приоритета и нам
нужно решить в каком порядке вычислять выражение.
Согласно правилам выражение \fC9 + 5 + 3\fP эквивалентно \fC(9 + 5) + 3\fP, 
аналогично \fC9 - 5 - 3\fP эквивалентно \fC(9 - 5) - 3\fP.
Когда операнд подобно \fC5\fP имеет операторы с двух сторон,
необходимо некоторое соглашение что бы решить какой оператор относится к данному операнду.
Для человека данный момент очевиден. Но его следует сделать понятным также и для машины.
Мы говорим что оператор \fC+\fP лево-ассоциативный,
потому что операнд имеющий по обе стороны знак плюс,
принадлежит оператору который находится слева.
.PP
Другим примером служат право-ассоциативные операторы.
Например операция присваивания. То есть выражение \fCa = b = c\fP
эквивалентно \fCa = (b = c)\fP.
.NH 2
Приоритет операций
.PP
Рассмотрим выражение \fC9 + 5 * 2\fP.
Существует две возможные интерпретации этого выражения:
\fC(9 + 5)*2\fP или \fC9 + (5 * 2)\fP.
Очевидно что необходимы некоторые правила,
которые бы разрешали не однозначность.
.PP
Мы говорим что операция \fC*\fP имеет больший приоритет чем \fC+\fP,
если она получает свои аргументы раньше.
Таким образом деление и умножение имею более высокий приоритет,
чем вычитание и сложение. То есть операнд \fC5\fP относится к \fC*\fP.
.PP
Посмотрим на грамматику для арифметических выражений.
На данный момент мы имеем \fC4\fP арифметических операции,
каждая из которых является лево-ассоциативной.
Операции \fC*\fP и \fC/\fP имеют приоритет выше чем \fC+\fP и \fC-\fP.
Мы также используем скобки, что бы показать,
что приоритет выражения в скобках выше.
.RS
.nf
.CW

expr \(-> expr + term | expr - term | term
term \(-> term * factor | term / factor | factor
factor \(-> digit | ( expr ) | E
digit \(-> 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 

.fi
.RE
.PP
С помощью символа \fCЕ\fP мы обозначаем пустую продукцию.
.NH 2
Парсер рекурсивного спуска
.PP
Данный вид парсера обрабатывает грамматику в один проход слева на право.
Парсер получает токены от лексического анализатора, сканируя файл токен за токеном.
Синтаксический анализатор сверяет текущий токен, с его правилами грамматики.
Если есть совпадения, то он двигается дальше, проверяя приходящие токены на соответствие грамматике.
Это делается до тех пор пока не будет достигнут конец, либо найдена ошибка.
Данный вид парсера также называется предикативным.
Это название он получил в силу того, что следуя выбранному правилу грамматики,
он предполагает что следующий приходящий токен, должен быть такой же как и в выбранном правиле.
То есть если текущий токен не входит в выбранное правило, это определенно ошибка пользователя.
.LP
Рассмотрим простой пример, что бы прояснить работы предсказывающего парсера:
.RS
.nf
.CW

stmt \(-> for_expr | if_expr | ... | expr
for_expr \(-> for (optexpt; optexpr ; optexpr) stmt
optexpr \(-> expr | E
expr \(-> \fIописывает присваивание, арифметические и условные выражения\fP

.fi
.RE
.LP
Процесс синтаксического анализа происходит следующим образом:
.RS
.CW

for (i = 0; i < 10 ; i = i + 1) k = k + 1

.RE
.PP
Как уже говорилось ранее. Парсер получает токены от лексического анализатора.
Работа парсера начинается со стартового символа грамматики.
В данном примере, первый токен который придет от лексического анализатора будет \fCTOKEN_FOR\fP,
обозначающий ключевое слово \fCfor\fP.
Теперь следуя правилу для конструкции \fCfor\fP,
парсер предполагает что следующий токен должен быть \fC'(' (TOKEN_LPARNT)\fP.
Если следует совпадение, то продолжаем следовать правилу.
Теперь он будет проверять правило для \fCoptexpr\fP,
в данном случае идет присваивание, которая разрешена грамматикой.
Дальше мы смотрим на наличие токена \fC';' (TOKEN_SEMICOLON)\fP и т.д.
В конце, после обработки всего выражения, построится узел дерева для цикла \fCfor\fP.
.PP
Следует также упомянуть, что то что мы описали называется синтаксический управляемая трансляцией.
Если взглянуть на исходный файл парсера, но можно заметить что функции которые обрабатывают выражение
для for имеют точно такие же имена, что записанные в грамматике, так же как и порядок их вызова.
.PP
Функция \fCmatch()\fP сравнивает предполагаемый токен с текущим.
Следующий фрагмент псевдокода проясняет суть:
.RS
.nf
.CW

	match('for'); match('(');	
	optexpr(); match(';');
	optexpr(); match(';');
	optexpr(); match(')');
	stmt();
.fi
.RE
.NH 2
Устранение левой рекурсии
.PP
Для парсера рекурсивного существует возможность зацикливания.
Проблемы возникают с так называемой \fIлевой рекурсией\fP
.PP
Взглянем на одну из продукций описанных выше:
.RS
.CW
.nf

mult_expr \(-> mult_expr * term | term

.fi
.RE
.PP
Проблема заключается в том, что мы имеем в теле продукции терминал с таким именем что и в правой части.
Как уже говорилось мы используем синтаксически управляемую трансляцию,
то есть элементы продукций отображаются в код, как имена функций.
Для нас это означает что первой функцией которую парсер должен вызвать из
функции \fCmult_expr()\fP, является \fCmult_expr()\fP.
Таким образом парсер попадает в бесконечный цикл.
.PP
Чтобы решить данную проблему нам нужно немного переписать продукции данного вида.
Рассмотри нетерминал A с двумя продукциями:
.RS
.nf
.CW

A \(-> Aa | B

.fi
.RE
.PP
Где а и В являются последовательностью терминалов и нетерминалов,
которые не начинаются с А.
Продукции данного вида называются леворекурсивными.
Для устранения рекурсии перепишем данную продукцию следующим образом:
.RS
.nf
.CW 

A \(-> BR
R \(-> aR | E

.fi
.RE
.PP
Где нетерминал \fCR\fP и его продукция является \fIправо-рекурсивными\fP.
Теперь посмотрим на наш пример:
.RS
.nf
.CW

A <\(em> mult_expr
a <\(em> *term
B <\(em> term

.fi
.RE
.PP
Используя данное правило мы можем переписать грамматику следующим образом:
.RS
.nf
.CW

mult_expr \(-> term rest_mult
rest_mult \(-> * term rest_mult | E

.fi
.RE
.PP
Где \fCA\fP это \fCmult_expr\fP, \fCa\fP это \fC*term\fP, \fCB\fP является \fCterm\fP, \fCR\fP соответствует
\fCrest_expr\fP.
.PP
Теперь перепишем правила приведенные выше для операций \fC +, -, *, / \fP.
Напомним как выглядели первоначальные грамматики:
.RS
.nf
.CW

summ_expr \(-> summ_expr + mult_expr 
           | summ_expr - mult_expr 
           | mult_expr
mult_expr \(-> mult_expr * term 
           | mult_expr / term 
           | term
term \(-> digit | (summ_expr) | E
digit \(-> 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9

.fi
.RE
.LP
Преобразованная грамматика:
.RS
.nf
.CW

summ_expr \(-> mult_expr rest_summ
rest_summ \(-> + mult_expr rest_summ 
           | - mult_expr rest_summ | E
mult_expr \(-> term rest_mult
rest_mult \(-> * term rest_mult 
           | / term rest_mult | E
term \(-> digit | (summ_expr)
digit \(-> 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9

.fi
.RE
.PP
В преобразованной форме грамматика уже не является очевидной.
Но без этого преобразования мы бы не смогли написать парсер рекурсивного спуска.
.NH 2
Используемые правила грамматики
.RS
.nf
.CW

programme \(-> stmts
stmts \(-> stmt stmts_rest
stmts_rest \(-> stmt stmts_rest | E
stmt \(-> scope_expr
      | if_expr
      | for_expr
      | while_expr
      | break_expr
      | continue_expr
      | return_expr
      | declaration_expr
      | other_expr
      | unknown_expr
      declaration_expr \(-> process_function
      | process_matrix
      | process_variable
or_expr \(-> and_expr rest_or
rest_or \(-> '||' rest_or
and_expr \(-> rel_expr rest_and
rest_and \(-> '&&' rest_and
expr \(-> id '=' expr | or_expr
summ_expr \(-> mult_expr rest_summ
rest_summ \(-> '+' mult_expr rest_summ 
           | '-' mult_expr rest_summ | E
mult_expr \(-> term_expr rest_mult
rest_mult \(-> '*' term_expr rest_mult 
           | '/' term_expr rest_mult | E
term_expr \(-> term | '(' expr ')'
term \(-> integer | real | id
.fi
.RE
.NH 2
Аннотированное синтаксическое дерево
.PP
Как мы знаем, задача парсера состоит в построении дерева.
Главная функция \fCprogramme()\fP возвращает корень дерева, листья которого представляют терминалы,
а внутренние узлы нетерминалы.
.PP
Так же нам известно что дерево должно быть однозначным,
то есть каждое выражение может иметь только единственное представление в виде дерева.
.LP
В качестве примера посмотрим как строится узел для цикла \fCwhile\fP:
.RS
.nf
.CW

struct ast_node_while*
ast_node_while(struct ast_node *expr,
               struct ast_node *stmt)
{
	struct ast_node_while *while_node;
	
	return_val_if_fail(expr != NULL, NULL);

	while_node = ast_node_new(sizeof(*while_node));
	
	while_node->expr = expr;
	while_node->stmt = stmt;
	
	AST_NODE(while_node)->type   = NODE_TYPE_WHILE;
	AST_NODE(while_node)->child  = expr;
	AST_NODE(while_node)->destructor = ast_node_while_free;
	
	expr->parent = AST_NODE(while_node);
	stmt->parent = AST_NODE(while_node);
	
	return while_node;
}

.fi
.RE
.PP
Функция проверяет открывающую скобку, условие и закрывающую скобку.
Затем анализируется тело цикла, которое не может быт пустым.
Функция \fCop_expr\fP, в правилах грамматики служит стартовым символом для 
грамматики описывающей выражения использующие логический и арифметические операции.
Аналогично и для остальных узлов.
.NH 1
Таблица символов
.PP
В контексте нашей программы таблица символов очень проста.
И служит лишь для хранения переменных.
Так как интерпретатор это гибкий инструмент, как таковых типов у нас нет.
Любая переменная может менять свое значение на ходу.
.LP
Каждая программа имеет по крайне мере одну таблицу символов.
.RS
.nf
.CW

c = 0 

function my_function(a, b) {
	local a1, a2
	
	a1 = a + 1	
	a2 = a + b + c
	
	return a1 + a2
}

.fi
.RE
.LP
Грубо говоря для каждой области видимости переменных, создается своя таблица.
То есть переменные из старых таблиц перекрываются переменными из новой.
Переменная с находится в глобальной таблице.
Локальные переменные \fCa1, a2\fP находятся в новой таблице символов.
.PP
Таблица символов создается парсером.
Все таблицы держатся в односвязном списке, где последний элементом
является текущая таблица. А в самом начале находится глобальная таблица.
.RS
.ps 10
.vs 12
.PS
C: box "\fCtable N\fP"
arrow
box wid .9 "\fCtable N-1\fP"
move .2
"\fC...\fP"
move .2
box "\fCtable 2\fP"
arrow
G: box "\fCtable 1\fP"
move down .2 from C.s "\fCCurrent table\fP"
move down .2 from G.s "\fCGlobal table\fP"
.PE
.ps
.vs
.ce
\fBРис. 3.\fP Для каждого нового пространства создается своя таблица символов

.RE
.PP
Следующая часть кода показывает обработку области видимости:
.RS
.nf
.CW

static struct ast_node*
process_scope(void *opaque)
{
	struct ast_node *stmt;
	struct ast_node_stub *stub_node;
	struct scope_ctx *helper;
		
	stmt = stmts(opaque);	
		
	return stmt;
}

.fi
.RE
.PP
Код был значительно упрощен. Когда парсер находит \fC`{'\fP он вызывает \fCscope_scope()\fP
чтобы обработать область видимости. В данном случае мы решили не создавать новую таблицу символов
для каждого нового пространства. Таким образ здесь только собираются инструкции которые находятся между
\fC`{'\fP и \fC`}'\fP. Все переменные будут помещены в глобальную таблицу символов.
.LP
Основная структура хранящая информацию о переменной:
.RS
.nf
.CW
 
struct symbol {
        value_t                 v_type;
        char                    *name;
        union {
                double          digit;
                char            *string;
                gsl_vector      *vector;
                gsl_matrix      *matrix;		
        };

        release_t               destructor;
};
.fi
.RE
.NH 2
Поиск символов
.PP
Таблица символов использует хэш в качестве бэкенда.
Поэтому когда мы ищем символ в таблице символов, мы используем хэш функции.
.PP
Функции используемый для поиска символов:
.RS
.nf
.CW

struct symbol* symbol_table_lookup_top(char *name);
struct symbol* symbol_table_lookup_all(char *name);

.fi
.RE
.PP
Первая ищет символ только в текущей таблице. А вторая просматривает все.
.NH 1
Таблица функций
.PP
В нашей программе функции хранятся в отдельной таблице,
вместе с областью видимости своих локальных переменных.
Функции можно разделить на пользовательские и библиотечные.
Оба типа функций содержатся в одной таблице.
При запуске программы таблица функций инициализируется библиотечными функциями.
У библиотечных функций отсутствует тело функции.
.LP
Структура содержащая информацию о функции:
.RS
.nf
.CW

struct function {
        char                    *name;
        unsigned int            is_lib;
        unsigned int            nargs;
        struct symbol           **args;
        struct symbol_table     *scope;
        struct ast_node         *body;
        lib_handler_type_t      handler;
};

.fi
.RE
.
.PP
\fIAPI\fP\** для работы с функциями и символами похожи.
Таблица функций также использует хэш.
Когда пользователь вызывает функцию мы ищет ее в таблице.
Если ее там нет, то сообщаем об ошибке. 
Для того что бы пояснить как происходит обработка функций,
нам придется забежать немного вперед. Посмотрим как обрабатывается узел представляющий функцию при обходе дерева.
.FS
\fBAPI\fP (application programming interface) \(em 
набор готовых классов, процедур, функций, структур и констант, предоставляемых приложением (библиотекой, сервисом) для использования во внешних программных продуктах. 
.FE
.RS
.nf
.CW

static void
traverse_func_call(struct ast_node *node)
{
	struct function *function;
	struct ast_node_func_call *func_node;
	
	return_if_fail(node != NULL);
	
	func_node = (struct ast_node_func_call *)node;
	
	function = function_table_lookup(func_node->name);
	
	if (function->is_lib) {

		perform_lib_function(function, func_node->args);

	} else {
		symbol_table_set_scope(function->scope);
		
		perform_custom_function(function,func_node->args);
	
		symbol_table_pop();
	}				
}

.fi
.RE
.PP
Сначала мы достаем функцию из таблицы. Затем смотрим является ли она библиотечной или пользовательской.
Как уже говорилось пользовательские функции содержат в себе таблицу символов для локальных переменных.
Поэтому мы сперва устанавливаем эту таблицу символов, чтобы наши локальные переменные стали видны.
Нам также необходимо инициализировать аргументы функции.
Поле обработки функции мы выталкиваем таблицу для локальных переменных.
Теперь текущей таблицей символов остается глобальная таблица.
.RS
.nf
.CW

static void
perform_lib_function(struct function *func,
                     struct ast_node **args)
{
	struct eval *eval;
	struct symbol *sym;
	value_t v_type;
	void *result;
	int ok;

	perform_init_args(func, args);
	
	func->handler(func, &v_type, &result);

	eval = eval_new(TAG_CONST, v_type, result);

	push(eval);
}

.fi
.RE
.PP
Данная функция показывает обработку библиотечных функций.
Функция была немного упрощена.
Сперва инициализируем аргументы, затем вызываем обработчик.
Дальше все как обычно, полученное значение помещается в стэк.
Так выглядит \fChandler\fP для фнкции \fCsin\fP в немного упрощенном варианте:
.RS
.nf
.CW

int
libcall_sin(struct function *func,
            value_t *v_type, void **result)
{
	double *dg;

	dg  = umalloc(sizeof(double));
	*dg = sin(func->args[0]->digit);

	*v_type = VALUE_TYPE_DIGIT;	
	*result = dg;
	
	return TRUE;
}

.fi
.RE
.PP
Внутри обработчика мы вызываем функцию \fCsin\fP из стандартной библиотек языка Си.
.NH 1
Обход дерева
.PP
Мы подошли к последней фазе.
Здесь мы имеет синтаксическое дерево,
полученное от парсера. Которое является эквивалентом исходной программы.
Теперь имея данное представление программы в виде дерева,
мы можем выполнять инструкции. 
.PP
Обход дерева совершаемый нами с целью получения результат называется обход в глубину.
То есть мы начиная с корня с пускаемся в дочерние узлы пока это возможно.
Дойдя до листьев дерева, мы выполняем необходимы вычисления и поднимаемся обратно.
.LP
Пример функции для обхода дерева:
.RS
.nf
.CW

static void
traverse_op(struct ast_node *node)
{
	struct ast_node_op *op;
	struct eval *a,*b, *c;
	struct symbol *sym;
	
	op = (struct ast_node_op *)node;

	traversal(op->left);
	traversal(op->right);
		
	b = pop();
	a = pop();
	
	c = eval_add_op(a, b, op->opcode);
		
	push(c);
}

.fi
.RE
.PP
Для каждого узла дерева существует своя функция обхода.
Данная функция вызывается когда мы попадаем в узел соответствующий арифметическим или логическим операциям.
Сперва мы посещаем дочерние узлы(в данном случае в порядке слева на право, но в целом не важно).
Вернувшись обратно, выталкиваем  значение из "стека" и производим вычисления.
Далее результат вычислений помещается опять в "стек". В итоге, то что осталось в стеке печатается как результат.
.RS
.ps 10
.vs 12
.PS
circlerad = .15
movewid = .3
moveht = .6
down
C1: circle "\fC+\fP"
move down from C1
{ move left;  C2: circle  "\fC*\fP" }
{ move right; C3: circle "\fC5\fP" } 
move down from C2
{ move left;  C4: circle "\fC2\fP" }
{ move right; C5: circle "\fC3\fP" }
arrow from C1 to C2 chop
arrow from C1 to C3 chop
arrow from C2 to C4 chop
arrow from C2 to C5 chop
spline -> from C1.n + (-.1, .1) to C2.w + (-.2, 0) \
then to C4.w  + (-.2, 0) \
then to C4.s  + (0, -.2) \
then to C4.se + (.2 , 0) \
then to C2.s  + (0, -.2) \
then to C5.w  + (-.2, 0) \
then to C5.s  + (0, -.2) \
then to C5.e  + (.2, 0)  \
then to C2.e  + (.2, 0)  \
then to C1.s  + (0, -.2) \
then to C3.w  + (-.2, 0) \
then to C3.s  + (0, -.2) \
then to C3.e  + (.2, 0)  \
then to C1.e  + (.2, 0)
.PE
.ps
.vs
.ce
\fBРис. 4.\fP Схема обхода дерева
.RE
.PP
Мы чуть не забыли упомянуть о \fIсемантическом анализе\fP.
Задача семантического анализа состоит в проверке синтаксического дерева.
Основной задачей является проверка типов переменных.
Поскольку у нас интерпретатор, то мы можем не проверять типы переменных как это делается например для языка С.
Поэтому обход дерева и семантический анализ объединяются в одни проход.
.NH 1
Библиотека GSL
.PP
Для работы с матрицами и векторами мы используем библиотеку \fIGSL\fP.
GSL написана на языке С, для численных вычислений в прикладной математики и науке.
То есть представляет собой широкий набор функций, которые разбиты на библиотеки.
В частности мы используем из всего этого множества библиотеку \fIBLAS\fP\**.
BLAS дает высокоуровневый интерфейс для операций над матрицами и векторами.
.FS
\fBBLAS\fP \(em Basic Linear Algebra Subprograms
.FE
.LP
Существуют 3 уровня операций:
.RS
.IP "\fBLevel 1\fP" 2
Операции над векторами \fCy = \\alpha x + y\fP
.IP "\fBLevel 2\fP" 2
Операции матрица-вектор , т.е \fCy = \\alpha A x + \\beta y\fP 
.IP "\fBLevel 3\fP" 2
Операции над векторами \fCC = \\alpha A B + C\fP
.RE
.LP
В нашей программе мы используем данную библиотеку следующим образом:
.RS
.nf
.CW

gsl_vector*
libm_vector_matrix_mult_op(gsl_vector *a, 
                           gsl_matrix *b,
                           opcode_type_t op)
{
	gsl_permutation *pm;
	gsl_matrix *inv, *c, *mx;
	gsl_vector *vc;
	int err, ok, signum;

	switch(op) {	
	case OPCODE_MULT:
		vc  = gsl_vector_alloc(b->size1);
		gsl_blas_dgemv(CblasTrans, 1.0, b, a, 0.0, vc);	
		break;
	case OPCODE_DIV:
		pm = gsl_permutation_alloc(b->size1);
		vc = gsl_vector_alloc(b->size1);
		
		matrix_init(&mx, b);

		gsl_linalg_LU_decomp(mx, pm, &signum);
		gsl_linalg_LU_solve(mx, pm, a, vc);
		
		gsl_permutation_free(pm);
		gsl_matrix_free(mx);		
		 
		break;
	default:
		error(1, "nonconformant operation");
	}
	
	return vc;		
}

.fi
.RE
.PP
Функция была упрощена. Данная функция принимает в качестве параметров матрицу и вектор и производит вычисления.
.NH 1
IEEE\** 754
.PP
Это технический стандарт для вычислений с плавающей точкой принятый в 1985 году Институтом инженеров по электронике и электротехнике. Кратко опишем что данный стандарт определяет:
.FS
\fBIEEE\fP \(em Institute of Electrical and Electronics Engineers.
.FE
.RS

.IP \(bu 2
\fIАрифметические форматы\fP: представления двоичном и десятичной форме данных с плавающей точкой,
то есть конечные числа(включая также значащие нули, денормализованные числа),
бесконечности и NaN'ы.
.IP \(bu
\fIПравила округления\fP: свойства которые должны быть удовлетворены во время вычислений и преобразований.
.IP \(bu
\fIОперации\fP: арифметические и другие.
.IP \(bu
\fIОбработка исключений\fP: деление на ноль, переполнение и др.
.IP \(bu
Методы, которые используются для преобразования числа в процессе математических операций.

.RE
.LP
Представление числа с плавающей точкой:
.ps 10
.vs 12
.PS
boxwid = .18
boxht = .18
.CW
Sign: [ 
	box "0"
]
Exponent: [
	box "0" 
	box "1"
	box "1"
	box "1"
	box "1"
	box "1"
	box "0"
	box "0"
]
Fraction: [
	box "0"
	box "1"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"	
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
	box "0"
]
L0: line up .1 from Sign.n + (0, 0.05); move .1 "sign"
L1: line up .1 from Exponent.nw + (0, 0.05)
L2: line up .1 from Exponent.ne + (-0.02, 0.05)
L3: line "exponent(8-bit)" "" from L1.n to L2.n; 
L4: line up .1 from Fraction.nw + (0.02, 0.05)
L5: line up .1 from Fraction.ne + (0, 0.05)
L6: line "fraction(23-bit)" ""from L4.n to L5.n
move down .1 from Sign.s + (0, -0.05); "31"
move down .1 from Exponent.se + (-.1, -0.05); "23"
move down .1 from Fraction.se + (-.1, -0.05); "0"
.PE
.ps
.vs
.ce
\fBРис. 5.\fP Представление числа 0.15625 в виде числа с плавающей точкой IEEE 754 

.PP
Следует также отметить что сопроцессор Intel 8087 выпущенный компанией
Intel в 1980 году стал основой для стандарта IEEE 754. 
Данный сопроцессор обеспечивал два основных формата для чисел с плавающей точкой \(em 32 и 64 битные.
А также формат расширенной точности \(em 80 бит.
.NH 1
Описание языка
.PP
Напомним что наш язык работает с числами с плавающей точкой.
Есть некоторые сходства с языком С. И так посмотрим что есть.

.IP "\fBКОНСТАНТЫ\fP"
.RS
Внутри числа представлены в виде чисел с плавающей точкой имеющие двойную точность.
То есть целые числа которые пользователь может ввести скажем число \fC256\fP отобразится в \fC256.000000\fP.
Константами могут быть также строка, матрица и вектор. Строки начинаются и заканчиваются двойным апострофом `\fC"\fP'.
Пример вектора \fC[1,4,2]\fP. Матрица как и вектор начинается с открывающей скобки,
затем через запятую перечисляются элементы. Единственно отличие это размерность,
матрицы имеют две размерности. Пример матрицы \fC[1,2;8,6]\fP.
.RE
.IP "\fBПЕРЕМЕННЫЕ\fP"
.RS
Переменные начинаются с буквы или символа подчеркивания,
с последующим произвольным числом символов подчеркивания, цифр и букв.
Есть также специальная переменная \fCans\fP которая содержит результат последнего вычисления.
Изначально \fCans\fP содержит путь к рабочей директории.
.RE
.IP "\fBКОММЕНТАРИИ\fP"
.RS
Комментарии начинаются с символа \fC#\fP.
Символы после \fC#\fP пропускаются вплоть до конца строки.
Символ конца строки не является частью комментария.
.RE
.IP "\fBВЫРАЖЕНИЯ\fP"
.RS
Самым простым выражением в нашем языке является константа.
В остальном имеются сходства с другими языками.
Далее \fCexpr\fP ссылается на полное выражение, а \fCvar\fP на переменную.
В частности переменная это всего лишь \fCid\fP \(em идентификатор.
Для того что бы обратится к элементам вектора достаточно ввести \fCid[idx]\fP,
для матрицы \fCid[idx1][idx2]\fP.

.IP "\fCexpr + expr\fP" 5n 
Результатом выражения является сумма двух выражений.

.IP "\fCexpr - expr\fP" 
Результатом выражения является разность двух выражений.

.IP "\fCexpr * expr\fP"
Результатом выражения является произведение двух выражений.

.IP "\fCexpr / expr\fP"
Результатом выражения является частным двух выражений.

.IP "\fCexpr ^ expr\fP"
Результатом выражения является первое выражение возведенное во второе.
Значение второго должно быть целым. Если первое выражения является матрицей,
то она должны быт квадратной.

.IP "\fCvar = expr\fP"
Переменной присваивается выражение.

.IP "\fCexpr1 < expr2\fP"
Результатом является \fC1\fP если \fCexpr1\fP строго меньше чем \fCexpr2\fP.

.IP "\fCexpr1 <= expr2\fP"
Результатом является \fC1\fP если \fCexpr1\fP меньше либо равно \fCexpr2\fP.

.IP "\fCexpr1 > expr2\fP"
Результатом является \fC1\fP если \fCexpr1\fP строго больше \fCexpr2\fP.

.IP "\fCexpr1 >= expr2\fP"
Результатом является \fC1\fP если \fCexpr1\fP больше либо равно\fCexpr2\fP.

.IP "\fCexpr1 == expr2\fP"
 Результатом является \fC1\fP если \fCexpr1\fP равно \fCexpr2\fP.

.IP "\fCexpr1 != expr2\fP"
Результатом является \fC1\fP если \fCexpr1\fP не равно \fCexpr2\fP.

.IP "\fCexpr && expr\fP"
 Результатом является \fC1\fP если оба выражения являются \fC1\fP.

.IP "\fCexpr || expr\fP"
Результатом является \fC1\fP если одно из выражения не нулевое.
.RE           
.LP

\fIСтаршинство операций\fP от имеющих наименьший приоритет к наибольшему:
.RS
.nf

\fC||\fP \(em лево-ассоциативная

\fC&&\fP \(em лево-ассоциативная

Операции отношения \(em лево-ассоциативные

Оператор присваивания \(em право-ассоциативный

\fC+\fP и \fC-\fP \(em лево-ассоциативные

\fC*\fP и \fC/\fP \(em лево-ассоциативные

\fC^\fP \(em право-ассоциативные
.fi
.RE
.IP "\fBИНСТРУКЦИИ\fP"
.RS
Инструкции упорядочивают вычисление выражений.
Инструкции запускаются когда встречается символ перевода строки,
который обозначает конец инструкции.
.IP "\fCexpression\fP"
Инструкции данного типа ведут себя следующим образом.
Если инструкции начинается с \fC<var><=> ...\fP то  она рассматривается как инструкция присваивания.
В противном случае выражение вычисляется и результат печатается на выход.

.IP "\fCif ( expression ) statement1 else statement2\fP"
Эта инструкция сначала вычисляет \fCexpression\fP, 
затем в зависимости от результата вычисляет либо \fCstatement1\fP либо \fCstatement2\fP (если присутствует).
То есть если выражение в скобках дает не нулевой результат то выполняется \fCstatement1\fP, 
в противном случае \fCstatement2\fP.

.IP "\fCwhile ( expression ) statement\fP"
Инструкция \fCwhile\fP будет запускать \fCstatement\fP пока значение \fCexpression\fP
не нулевое. Цикл прекращается если \fCexpression\fP обращается в ноль,
либо выполняется инструкция \fCbreak\fP.

.IP "\fCfor ( optexpr1 ; optexpr2 ; optexpr3 ) statement\fP"
Цикл \fCfor\fP контролирует запуск \fCstatement\fP следующим образом.
Сперва вычисляется \fCoptexpr1\fP.
Затем вычисляется \fCoptexpr2\fP если его значение не нулевое вычисляется \fCstatement\fP
В противном случае цикл не выполняется.
После запуска \fCstatement\fP вычисляется \fCoptexpr3\fP.
Если \fCoptexr1\fP или \fCoptexpr3\fP пропущены то на их месте не производится никаких вычислений.
Если пропущено \fCoptexpr2\fP то это эквивалентно замене \fCoptexpr2\fP на \fC1\fP.
Следующий код является эквивалентом цикла \fCfor\fP:

.RS
.CW
.nf
optexpr1;
while (optexpr2) {
	statement;
	optexpr3;
}
.fi
.RE

.IP "\fCbreak\fP"
Инструкция прерывающая цикл.

.IP "\fCcontinue\fP"
Начинает новую итерацию в цикле.

.IP "\fCreturn\fP"
Инструкция выхода из функции.
Для возвращения значени из функции используется \fCreturn expr\fP.
.RE
.IP "\fBФУНКЦИИ\fP
Функции нужны для определения вычислений которые используются позже.
Функции могут возвращать или не возвращать значения.
Определяются функции следующим образом:
.RS
.nf
.CW

\fBfunction\fP fname(args) { \\newline
	\fBlocal\fP vars
	
	statement_list
}

.fi
.RE
Аргументы функции перечисляются через запятую.
То есть \fCarg1, arg2,...,argN\fP.
Список локальных переменных является необязательным.
Объявляются они как \fClocal var1, var2,...,varN\fP.
Тело функции представляет собой список инструкций.
Есть также так называемые библиотечные функции:
\fCsin(), cos(), ln(), exp()\fP.
.IP "\fBПРИМЕРЫ\fP"
Решение дифференциальных уравнений методом Рунге-Кутты:
.RS
.nf
.CW

# RK4

t0 = 0.0
tn = 0.2
h  = 0.005
y0 = 1.0

function f(t,y) {	
	return exp(t)
}

function deriv(t) {
	return exp(t)
}
        
len = (tn - t0) / h 

y = vector(len)
dy = vector(len)
err = vector(len)

i = 0
dy[i] = y0
y[i] = deriv(t0)
err[i] = dy[i] - y[i]

i = i + 1

while (i < len) {

        k1 = h * f(t0, y0)
        k2 = h * f(t0 + 0.5 * h, y0 + 0.5 * k1)
        k3 = h * f(t0 + 0.5 * h, y0 + 0.5 * k2)
        k4 = h * f(t0 + h, y0 + k3)

        yn = y0 + 1/6 * (k1 + 2*k2 + 2*k3 + k4)

        d = deriv(t0)

        t0 = t0 + h
        y0 = yn 
 
        dy[i] = yn
        y[i] = d
        err[i] = dy[i] - y[i]

        i = i + 1    
}

"Vector dy:"
dy

"Vector y:"
y

"Vector err:"
err

.fi
.RE
.bp
.ce
.B
Заключение
.PP
В работе были использованы базовые принципы так называемой теории компиляторов,
для создания интерпретируемого языка. На данный момент с помощью данного языка 
решена задача нахождения решения обычного дифференциального уравнения методом Рунге-Кутты.
Код находится в примерах в разделе описания языка. 
.bp
.LP
\fBЛитература\fP
.IP [1] 2
Alfred V. Aho, Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman Compilers: Principles, Techniques, and Tools:
Addison Wesley, 2006
.IP [2]
Michael L. Scott Programming language pragmatics: Morgan Kaufman Pablishers
.IP [3]
LitePAC [Электронный ресурс]:
\(em Режим доступа: http://www.litepac.org/ \(em Дата посещ. 23.06.2012
.IP [4]
.nf
Bc [Электронный ресурс]:\(em Режим доступа:
http://en.wikipedia.org/wiki/Bc_programming_language \(em Дата посещ. 23.06.2012
.fi
.IP [5]
.nf
Tiny C Compiler [Электронный ресурс]:\(em Режим доступа: 
http://bellard.org/tcc/ \(em Дата посещ. 23.06.2012
.fi


